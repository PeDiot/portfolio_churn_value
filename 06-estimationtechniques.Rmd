---
output: html_document2
editor_options: 
  chunk_output_type: console
---

```{r echo=FALSE}
knitr::opts_chunk$set(
  fig.align = "center", 
  echo = FALSE, 
  message = FALSE, 
  comment = FALSE, 
  warning = FALSE, 
  fig.topcaption = TRUE
)
```

```{r}
source("functions.R", 
       encoding = "UTF-8")
```

```{r}
data_path <- "./data/"
backup_path <- "./backup/"
```


```{r}
library(tidyverse)    # data wrangling
library(ggplot2)      # fancy plots 
library(ggsci)        # fancy palettes
library(ggpubr)       # arrange plots

library(knitr)        # kable
library(kableExtra)   # fancy tables

library(survival)     # Kaplan-Meier
library(survminer)    # display survival plots 
```

```{r}
theme_set(theme_minimal())
```


# Estimation techniques {#estimation}

This chapter explains the different methods used to model a portfolio of customers as well as their related risk of attrition and the overall value of the portfolio. In a first part, clustering techniques are implemented to identify segments of customers based on services and account variables. Then, survival models are fitted to estimate each customer's survival in the firm's portfolio. The selected model can also be used to assess the effects of each variable on the risk of churn. Finally, we answer the study's problematic by computing an estimated value of the portfolio. The latter is calculated using a corporate formula and takes customers' monthly fees and survival probabilities as inputs. The estimated portfolio value is not cost-adjusted there is no information on consumers' costs in the data set.

## Feature selection {#featureselection}

Before fitting any survival model or clustering algorithm to the data, the initial step consists in selecting variables that are discriminating in terms of churn hazard. Based on Kaplan-Meier analysis depicted in section \@ref(churndescstats), we have a general overview of features which influence the survival probability. In other words, our feature selection method relies on results obtained with descriptive statistics. 

Table \@ref(tab:selectedfeatures) shows the selected variables for 5 random observations extracted from the data set. It can be noted that these features are related to account or service information, apart from `Dependents` which indicates whether the client lives with any dependents (children, parents, etc) and `Senior_Citizen`. Furthermore, 9 out of the 10 selected variables are categorical which implies that the estimation results could be used to compare different groups of client. `Monthly_Charges` is the only quantitative variable used to fit clustering models and survival regressions. 

```{r selectedfeatures}
load(file = paste0(data_path, "telco_cleaned.RData"))
cleaned_data %>%
  select(c(
    "Senior_Citizen", 
    "Dependents", 
    "Phone_Service", 
    "Internet_Service", 
    "Online_Security", 
    "Online_Security", 
    "Online_Backup", 
    "Tech_Support", 
    "Contract", 
    "Payment_Method", 
    "Monthly_Charges"
  )) %>%
  sample_n(5) %>%
  mykable(title = "Explanatory variables used in survival models and cluster analysis") %>%
  scroll_box(width = "100%", box_css = "border: 0px;")
```

## Portfolio segmentation 

Customer segmentation helps decision makers having a better understanding of their clients. It can then be used to enhance marketing strategies via personalization. In other words, segmentation can lead to target customers with offers and incentives personalized to their wants, needs and preferences. In order to make segmentation more accurate, it is more appropriate to use cluster analysis than predetermined thresholds or rules, even more when we have several variables at our disposal. In this context, this section focuses on applying clustering methods on features displayed in table \@ref(tab:selectedfeatures), apart from `Monthly_Charges`. 

### Transforming qualitative variables into principal axes

The variables selected to perform cluster analysis being categorical, it is needed to transform them into continuous features. To that end, multiple correspondence analysis (MCA) is performed. MCA is a dimension reducing method which takes multiple categorical variables and seeks to identify associations between levels of those variables. MCA aims at highlighting features that separate classes of individuals, while determining links between variables and categories. To that end, MCA keeps the core information by the means of principal components which are projected axes [@MCA].

Here, the main objective of applying MCA being to obtain continuous features, it is decided to keep as many axes as it takes to have at least 80% cumulated variance. In other words, we want the principal components to gather enough customer-related information. After having processed the `MCA` function from the R package `FactoMineR` [@FactoMineR2008], 10 principal components are required to keep more than 80% cumulated variance as depicted by figure \@ref(fig:mcascreeplot).

```{r mcascreeplot, fig.cap="Variance explained and cumulated variance after MCA"}
knitr::include_graphics(path = "./imgs/mca_screeplot.png")
```

Now the 10 continuous axes are identified, the next step consists in retrieving the customers' coordinates onto those axes to then perform cluster analysis. 

```{r}
load(file = paste0(backup_path, "clustering/res.mca.RData"))
mca_df <- cbind(CustomerID = cleaned_data$CustomerID, 
      res.mca2$ind$coord) %>%
  as.data.frame() 
rownames(mca_df) <- NULL
mca_df%>%
  sample_n(5) %>%
  mykable(title = "The 10 principal axes obtained by MCA")
```

Note that a more in-depth visualisation of those 10 principal components can be found in section \@ref(mcaappendix) in the appendix. This charts depict the percent contribution of each variable's categories to the principal axes, which is helpful to have a better understanding of MCA results.


### Hierarchical clustering on principal components

Multiple correspondence analysis has led us to convert the categorical variables related to account and services information into 10 numerical projected axes. The stake here is to use the customers' projections onto the MCA components in order to identify groups of individuals through clustering techniques. As a reminder, clusters are expected to discriminate between customers based on the services they use and the type of plan they are enrolled into. The method implemented in this part relies on hierarchical clustering on principal components (HCPC).

#### Optimal number of clusters {-}

The key parameter to optimize when applying clustering methods is the number of clusters $k$. When using the `HCPC` function from `FactorMineR`, the `nb.clust` parameter is set to -1 so that the tree is automatically cut at the suggested level. More precisely, the function first builds a hierarchical tree. Then the sum of the between-cluster inertia is calculated for each partition. The suggested partition is the one with the higher relative gain in inertia. Intuitively, the underlying objective is to choose a number of clusters leading to $k$ well distinguished groups. Here, the between-cluster inertia is the metric measuring the amount of variability between clusters.

```{r btwinertia, fig.cap="Relative gains in between-cluster inertia given the partition"}
knitr::include_graphics(path = "./imgs/btw_inertia.png")
```

#### Cluster visualisation {-}

```{r}
load(file = paste0(backup_path, "clustering/cluster_prop.RData"))
clust_prop %>%
  mykable(title = "Customer repartition across the 3 clusters")
```


```{r clusterplot, fig.cap="Cluster visualisation onto the 2 first MCA axes"}
knitr::include_graphics(path = "./imgs/cluster_plot.png")
```

See figure \@ref(fig:clusterplots) in the appendix for cluster visualisations onto the other MCA principal axes.

#### Cluster description {-}

```{r monthlychargesclust, fig.cap="Monthly charges repartition across clusters"}
knitr::include_graphics(path = "./imgs/monthly_charges_clust.png")
```

```{r catvarsclust, fig.cap="Customer categorical features based on cluster"}
knitr::include_graphics(path = "./imgs/cat_vars_clust.png")
```

## Churn analysis 

Estimating the risk of attrition related to each customer is an essential step to model the firm's portfolio. In this context, survival models can be implemented with a view of deriving a predicted churn risk and survival function for each client. One the one hand, these predictions can be used to identify loyal consumers and make appropriate decisions. For instance, it might be relevant to offer benefits to a high-value client with a high estimated churn risk. On the other hand, a customer's survival probability at time $t$ represents the chance that this very customer be active in the portfolio at time $t$. This measure is helpful to compute the estimated value of the portfolio in the last section.

Before presenting the estimation results, it seems important to recall that `Tenure_Months` and `Churn_Value` can be seen as a pair of time and event variables used as target in survival models. 

```{r survtarget}
cleaned_data %>%
  select(c(
    "CustomerID", 
    "Tenure_Months",
    "Churn_Value"
  )) %>%
  sample_n(5) %>%
  mykable(title = "Time and event variables for survival models") 
```

### The Cox model 

When it comes to choose an estimation method on survival data, the Cox PH model appears to be an interesting first choice. As explained in chapter \@ref(duration), this semi-parametric model makes no assumption regarding the nature of the baseline hazard function $\lambda_0(t)$. The parametric part only relies in the modelling of the effect of some covariates on the hazard function $\lambda(t)$ (see section \@ref(coxph) for more details). 

#### Fitting the model on the selected features {-}

Using the `coxph` function from the `survival` R library [@survival-book], we are able to train a Cox model on the feature vector identified in section \@ref(featureselection). Once the model fitted, it seems relevant to evaluate its performance on the train data set. Table \@ref(tab:lrtest) compares the model's log-likelihood to the constrained model's. Given the very low p-value, it can be assumed that the Cox model better fits the data than a model with only the intercept. 

```{r lrtest}
load(file = paste0(backup_path, "survival/cox_metrics.Rdata"))
cox_metrics$lrtest %>%
  mykable(title = "Log-likelihood ratio test")
```

Concordance index $c$ is another metric to assess the performance of models which produces risk scores and is defined as the probability to well predict the order of event occurring time for any pair of instances. For the Cox model, the C-index obtained on the training set is $c \approx 0.865 \pm 0.004$, which is more than satisfying.


#### Marginal effects {-}

In the Cox model, the relative hazard between two observations is assumed to be constant over time. As a consequence, the relative hazard becomes $\exp \hat{\beta}$ for both dummy and continuous variables. For instance regarding figure \@ref(fig:coxmarginaleffects), the relative hazard ratio between customers with a two-year contract and those with a month-to-month contract is 0.046, meaning that the latter group is 22 times more prone to churn than the former. Also, month-to-month clients are about 5 times more likely to churn than customers enrolled in one-year plan.

```{r coxmarginaleffects, fig.cap="Marginal effects obtained with the Cox PH model"}
knitr::include_graphics(path = "./imgs/cox_ggforest.png")
```

#### Estimating churn hazard {-}

```{r coxdataviz, fig.cap="Aggregated churn hazard, survival and cumulative hazard functions estimated by Cox model"}
knitr::include_graphics(path = "./imgs/cox_data_viz.png")
```

```{r coxclust, fig.cap="Aggregated churn hazard, survival and cumulative hazard functions for each cluster"}
knitr::include_graphics(path = "./imgs/churn_surv_clust.png")
```


### Model comparison

## Portfolio value estimation

### Mathematical formulation 

### Customer lifetime raw value

```{r}
load(file = paste0(backup_path, "custvalues/", "custValues_8pct", ".RData"))
load(file = paste0(backup_path, "custvalues/", "custValues_clust", ".RData"))
```


```{r custValues}
tab <- custValues %>%
  pull(v) %>%
  summary() %>%
  unclass() %>%
  data.frame(check.names = FALSE, 
             stringsAsFactors = FALSE)
colnames(tab) <- " " 

tab %>%
  mykable(title = "CLRV Statistical summary", 
          transp = T)
```


```{r custrawvaldens, fig.cap="Customer lifetime raw value - Density and evolution by number of months"}
knitr::include_graphics(path = "./imgs/cust_lifetime_raw_value.png")
```

### Cluster contribution to the portfolio value

```{r totValclust}
tab <- custValues_clust %>%
  group_by(cluster) %>%
  summarise_at(vars(starts_with("v")), 
               function(v){sum(v) %>%
                   format(big.mark = ",")})  %>%
  mutate(prop = clust_prop[1, ]) %>%
  relocate(prop, .after = "cluster")
colnames(tab) <- c("Cluster", "Proportion (%)", "V lower", 
                   "V", "V upper")
tab %>%
  mykable(title = "Total CLRV per cluster", 
          align = rep("c", 5))
```

```{r custValuesclust}
lapply(seq(1, 3), 
       function(c){
         tmp <- custValues_clust %>%
           filter(cluster == c) %>%
           pull(v) %>%
           summary() %>%
           unclass() %>%
           data.frame(check.names = FALSE, 
                       stringsAsFactors = FALSE)
         colnames(tmp) <- paste("Cluster", as.character(c))
         tmp %>% 
           t() %>%
           as.data.frame()
       }) %>%
  bind_rows() %>%
  mykable(title = "CLRV statistical summary for each customer segment")
```


### Simulations 


