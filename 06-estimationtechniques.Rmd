---
output: html_document2
editor_options: 
  chunk_output_type: console
---

```{r}
# setwd("C:/Users/pemma/OneDrive - Université de Tours/Mécen/M2/S2/04 - 3R/portfolio_churn_value")
```


```{r echo=FALSE}
knitr::opts_chunk$set(
  fig.align = "center", 
  echo = FALSE, 
  message = FALSE, 
  comment = FALSE, 
  warning = FALSE, 
  fig.topcaption = TRUE
)
```

```{r}
source("functions.R", 
       encoding = "UTF-8")
```

```{r}
data_path <- "./data/"
backup_path <- "./backup/"
```


```{r}
library(tidyverse)    # data wrangling
library(ggplot2)      # fancy plots 
library(ggsci)        # fancy palettes
library(ggpubr)       # arrange plots

library(knitr)        # kable
library(kableExtra)   # fancy tables

library(survival)     # Kaplan-Meier
library(survminer)    # display survival plots 
```

```{r}
theme_set(theme_minimal())
```


# Estimation techniques {#estimation}

This chapter explains the different methods used to model a portfolio of customers as well as their related risk of attrition and the overall value of the portfolio. In a first part, clustering techniques are implemented to identify segments of customers based on services and account variables. Then, survival models are fitted to estimate each customer's survival in the firm's portfolio. The selected model can also be used to assess the effects of each variable on the risk of churn. Finally, we answer the study's problematic by computing an estimated value of the portfolio. The latter is calculated using a corporate formula and takes customers' monthly fees and survival probabilities as inputs. The estimated portfolio value is not cost-adjusted there is no information on consumers' costs in the data set.

## Feature selection {#featureselection}

Before fitting any survival model or clustering algorithm to the data, the initial step consists in selecting variables that are discriminating in terms of churn hazard. Based on Kaplan-Meier analysis depicted in section \@ref(churndescstats), we have a general overview of features which influence the survival probability. In other words, our feature selection method relies on results obtained with descriptive statistics. 

Table \@ref(tab:selectedfeatures) shows the selected variables for 5 random observations extracted from the data set. It can be noted that these features are related to account or service information, apart from `Dependents` which indicates whether the client lives with any dependents (children, parents, etc) and `Senior_Citizen`. Furthermore, 9 out of the 10 selected variables are categorical which implies that the estimation results could be used to compare different groups of client. `Monthly_Charges` is the only quantitative variable used to fit clustering models and survival regressions. 

```{r selectedfeatures}
load(file = paste0(data_path, "telco_cleaned.RData"))
cleaned_data %>%
  select(c(
    "Senior_Citizen", 
    "Dependents", 
    "Phone_Service", 
    "Internet_Service", 
    "Online_Security", 
    "Online_Security", 
    "Online_Backup", 
    "Tech_Support", 
    "Contract", 
    "Payment_Method", 
    "Monthly_Charges"
  )) %>%
  sample_n(5) %>%
  mykable(title = "Explanatory variables used in survival models and cluster analysis") %>%
  scroll_box(width = "100%", box_css = "border: 0px;")
```

## Portfolio segmentation 

Customer segmentation helps decision makers having a better understanding of their clients. It can then be used to enhance marketing strategies via personalization. In other words, segmentation can lead to target customers with offers and incentives personalized to their wants, needs and preferences. In order to make segmentation more accurate, it is more appropriate to use cluster analysis than predetermined thresholds or rules, even more when we have several variables at our disposal. In this context, this section focuses on applying clustering methods on features displayed in table \@ref(tab:selectedfeatures), apart from `Monthly_Charges`. 

### Transforming qualitative variables into principal axes

The variables selected to perform cluster analysis being categorical, it is needed to transform them into continuous features. To that end, multiple correspondence analysis (MCA) is performed. MCA is a dimension reducing method which takes multiple categorical variables and seeks to identify associations between levels of those variables. MCA aims at highlighting features that separate classes of individuals, while determining links between variables and categories. To that end, MCA keeps the core information by the means of principal components which are projected axes [@MCA].

Here, the main objective of applying MCA being to obtain continuous features, it is decided to keep as many axes as it takes to have at least 80% cumulated variance. In other words, we want the principal components to gather enough customer-related information. After having processed the `MCA` function from the R package `FactoMineR` [@FactoMineR2008], 10 principal components are required to keep more than 80% cumulated variance as depicted by figure \@ref(fig:mcascreeplot).

```{r mcascreeplot, fig.cap="Variance explained and cumulated variance after MCA"}
knitr::include_graphics(path = "./imgs/mca_screeplot.png")
```

Now the 10 continuous axes are identified, the next step consists in retrieving the customers' coordinates onto those axes to then perform cluster analysis. 

```{r}
load(file = paste0(backup_path, "clustering/res.mca.RData"))
mca_df <- cbind(CustomerID = cleaned_data$CustomerID, 
      res.mca2$ind$coord) %>%
  as.data.frame() 
rownames(mca_df) <- NULL
mca_df%>%
  sample_n(5) %>%
  mykable(title = "The 10 principal axes obtained by MCA")
```

Note that a more in-depth visualisation of those 10 principal components can be found in section \@ref(mcaappendix) in the appendix. This charts depict the percent contribution of each variable's categories to the principal axes, which is helpful to have a better understanding of MCA results.


### Hierarchical clustering on principal components

Multiple correspondence analysis has led us to convert the categorical variables related to account and services information into 10 numerical projected axes. The stake here is to use the customers' projections onto the MCA components in order to identify groups of individuals through clustering techniques. As a reminder, clusters are expected to discriminate between customers based on the services they use and the type of plan they are enrolled into. The method implemented in this part relies on hierarchical clustering on principal components (HCPC).

#### Optimal number of clusters {-}

The key parameter to optimize when applying clustering methods is the number of clusters $k$. When using the `HCPC` function from `FactorMineR`, the `nb.clust` parameter is set to -1 so that the tree is automatically cut at the suggested level. More precisely, the function first builds a hierarchical tree. Then the sum of the between-cluster inertia is calculated for each partition. The suggested partition is the one with the higher relative gain in inertia. Intuitively, the underlying objective is to choose a number of clusters leading to $k$ well distinguished groups. Here, the between-cluster inertia is the metric measuring the amount of variability between clusters.

```{r btwinertia, fig.cap="Relative gains in between-cluster inertia given the partition"}
knitr::include_graphics(path = "./imgs/btw_inertia.png")
```

Once the 3 groups identified by the clustering algorithm, one can determine customer repartition within those groups. Looking at table \@ref(tab:clustRepartition), cluster 2 represents the largest share of clients. This result is illustrated on figure \@ref(fig:clusterplot).

```{r clustRepartition}
load(file = paste0(backup_path, "clustering/cluster_prop.RData"))
clust_prop %>%
  mykable(title = "Customer repartition within the 3 clusters")
```

#### Cluster visualisation {-}

When performing hierarchical clustering on principal components, visualizing cluster repartition onto MCA axes is relevant to have a first idea on how each cluster if different from the others. Figure \@ref(fig:clusterplot) indicates that the three clusters are well separated in the $(F_1 ; F_2)$ plan. Cluster 1 is more concentrated than the others and take lower values onto dimension 1. The second group spreads over axis 1 and takes lower values on axis 2. Finally, cluster 3's position shows that its customers are characterized by categories which take positive values on both dimensions 1 and 2.

```{r clusterplot, fig.cap="Cluster visualisation onto the 2 first MCA axes"}
knitr::include_graphics(path = "./imgs/cluster_plot.png")
```

In the appendix, figure \@ref(fig:clusterplots) aims at visualizing clusters onto the other MCA principal components. Note that none of theses axes manages to separate the three clusters. This may be due to the low amount of variance each of these axes carries. 

#### Cluster description {-}

Once the 3 customer segments are identified on the MCA dimensions, it seems to be interesting to describe them according to the original features. To that end, the repartition of qualitative variables' categories is depicted on the following figure. Comparing figures \@ref(fig:clusterplot) and \@ref(fig:mcaplot), one can derive the following table in order to have a more precise idea on each segment. 

```{r}
data.frame(Cluster = c(1, 2, 3), 
           cat = c("Mailed_check, Internet_Service_No", 
                                           "Month-to-month, Electronic check, Tech_Support_No", 
                                           "Two year, Credit card, Tech_Support_Yes")) %>%
  rename(`Representative Categories` = cat) %>% 
  mykable(title = "The most representative categories for each cluster")
```

The first segment may be made up of customers having subscribed to minimum plans whith no internet service whereas segment 3 tends to represent clients with a large variety of services and long-term contracts. On the opposite, cluster 2 clients are enrolled in short-term plans with internet service but not technical options.


```{r mcaplot, fig.cap="MCA - Categories plot onto the two first axes"}
knitr::include_graphics(path = "./imgs/mca_plots.png")
```

Figure \@ref(fig:monthlychargesclust) depicts the differences in monthly charges paid by each customer segment. It can be observed that most of cluster 1 clients are enrolled in cheap subscriptions. On the contrary, the charges paid by the second and third clusters are higher and less homogeneous. Note that the median price is the same among these two groups.

```{r monthlychargesclust, fig.cap="Monthly charges repartition across clusters", out.width="70%", out.height="60%"}
knitr::include_graphics(path = "./imgs/monthly_charges_clust.png")
```

Since one of the study's purpose is to model customer churn, it is important to compare the churn rate across the 3 groups. Here, the striking point is that cluster 2 clients account for a large proportion of churners. Indeed, more than 75% of the clients having left the portfolio come from the second group. It can also be noted that cluster 1 and 3 are composed of more loyal customers as more than 70% of clients who did not churn are from those 2 groups.  

```{r catvarsclust, fig.cap="Churn repartition per cluster",out.width="60%", out.height="60%"}
knitr::include_graphics(path = "./imgs/churn_cluster_barplot.png")
```

#### Concluding remarks on portfolio segmentation {-}

With the aim of divide the portfolio into multiple groups based on categorical features, hierarchical clustering on principal components has led to identify three customer segments which can be broadly described as shown in the following table. 

```{r}
data.frame(Cluster = c(1, 2, 3), 
           Loyalty = c("High", "Low", "High"), 
           Value = c("Low", "High", "High"), 
           name = c("Silver", "Gold", "Platinum")) %>%
  rename(`Segment name` = name) %>% 
  mykable(title = "Portfolio segmentation summary") %>%
   column_spec(4, italic = T) %>%
    row_spec(2, bold = T)
```

*Gold* customers are valuable to the firm but are not loyal, making them the target segment. The objective would be to encourage them to stay in the portfolio longer.

## Churn analysis 

Estimating the risk of attrition related to each customer is an essential step to model the firm's portfolio. In this context, survival models can be implemented with a view of deriving a predicted churn risk and survival function for each client. One the one hand, these predictions can be used to identify loyal consumers and make appropriate decisions. For instance, it might be relevant to offer benefits to a high-value client with a high estimated churn risk. On the other hand, a customer's survival probability at time $t$ represents the chance that this very customer be active in the portfolio at time $t$. This measure is helpful to compute the estimated value of the portfolio in the last section.

Before presenting the estimation results, it seems important to recall that `Tenure_Months` and `Churn_Value` can be seen as a pair of time and event variables used as target in survival models. 

```{r survtarget}
cleaned_data %>%
  select(c(
    "CustomerID", 
    "Tenure_Months",
    "Churn_Value"
  )) %>%
  sample_n(5) %>%
  mykable(title = "Time and event variables for survival models") 
```

### The Cox model 

When it comes to choose an estimation method on survival data, the Cox PH model appears to be an interesting first choice. As explained in chapter \@ref(duration), this semi-parametric model makes no assumption regarding the nature of the baseline hazard function $\lambda_0(t)$. The parametric part only relies in the modelling of the effect of some covariates on the hazard function $\lambda(t)$ (see section \@ref(coxph) for more details). 

#### Fitting the model on the selected features {-}

Using the `coxph` function from the `survival` R library [@survival-book], we are able to train a Cox model on the feature vector identified in section \@ref(featureselection). Once the model fitted, it seems relevant to evaluate its performance on the train data set. Table \@ref(tab:lrtest) compares the model's log-likelihood to the constrained model's. Given the very low p-value, it can be assumed that the Cox model better fits the data than a model with only the intercept. 

```{r lrtest}
load(file = paste0(backup_path, "survival/cox_metrics.Rdata"))
cox_metrics$lrtest %>%
  mykable(title = "Log-likelihood ratio test")
```

Concordance index $c$ is another metric to assess the performance of models which produces risk scores and is defined as the probability to well predict the order of event occurring time for any pair of instances. For the Cox model, the C-index obtained on the training set is $c \approx 0.865 \pm 0.004$, which is more than satisfying.


#### Marginal effects {-}

In the Cox model, the relative hazard between two observations is assumed to be constant over time. As a consequence, the relative hazard becomes $\exp \hat{\beta}$ for both dummy and continuous variables. For instance regarding figure \@ref(fig:coxmarginaleffects), the relative hazard ratio between customers with a two-year contract and those with a month-to-month contract is 0.046, meaning that the latter group is 22 times more prone to churn than the former. Also, month-to-month clients are about 5 times more likely to churn than customers enrolled in one-year plan. When analysing the relative hazard ratios related to the payment method, it comes that clients who pay by electronic or mailed check are two times riskier to churn than those who pay by bank transfer. Furthermore, being enrolled in a plan with additional services like `Online_Security`, `Online_Backup` or `Tech_Support` tends to decrease the estimated churn risk. As for the effect of the `Internet_Service` covariate on the risk of attrition, it seems to be mitigated since clients who have a fiber optic internet connection are more than twice as likely to churn as those using a DSL internet connection. 

```{r coxmarginaleffects, fig.cap="Marginal effects obtained with the Cox PH model"}
knitr::include_graphics(path = "./imgs/cox_ggforest.png")
```

#### Estimation results {-}

Semi-parametric models aims at estimating the instantaneous hazard function given a baseline hazard and a set of covariates. The model outputs a risk prediction for each individual with a confidence interval. Then, the survival and cumulative hazard functions can be retrieved as explained in section \@ref(probabilities). When going deeper into the functions depicted in figure \@ref(fig:coxdataviz), it can be noticed some inconsistencies between the estimated churn hazard cumulative hazard functions. Given the cumulative churn hazard increases faster when the number of months is high and given the instantaneous hazard is supposed to be the cumulative hazard function's slope, the estimated churn hazard's shape should be convex. Thus, the Cox model does not manage to properly estimate the risk of churn. 

```{r coxdataviz, fig.cap="Aggregated churn hazard, survival and cumulative hazard functions estimated by Cox model"}
knitr::include_graphics(path = "./imgs/cox_data_viz.png")
```

Although the fitted model is not flawless, it can be interested to study the estimation differences between the 3 customer segments identified in the previous section. Looking at figure \@ref(fig:coxclust), one can conclude that *Gold* (cluster 2) clients are more prone to churn than others. The aggregated risk of attrition is indeed higher to such an extent that the cumulative churn hazard is exploding when the number of months is greater than 60. This being said, an efficient portfolio management would be to find strategies to reduce *Gold* customers' churn and increase their duration in the portfolio. 

```{r coxclust, fig.cap="Aggregated churn hazard, survival and cumulative hazard functions for each cluster"}
knitr::include_graphics(path = "./imgs/churn_surv_clust.png")
```

### Other survival models

As said in the previous part, the Cox model does not fit the data perfectly as it does not capture the churn hazard's actual shape. In this context, it seems relevant to fit other survival models and test how they perform in predicting the risk of attrition. It is firstly decided to train parametric survival models which consist in assigning a probability distribution to the hazard function (see section \@ref(parametric) for more details). To that end, one can use `flexsurv` [@flexsurv2016] which is and R package for parametric survival modelling. After having fitted the exponential, Weibull, gamma, log-logistic and log-normal models, no improvement can be observed with respect to the Cox model. Then, a machine learning approach can be adopted to model duration data using the random survival forest algorithm as explained in section \@ref(mlsurv). The `rfsrc` function from `randomForestSRC` [@randomForestSRC2008] is used to train the model after having determined the optimal node size and number of variables to try at each split with the `tune` function. Once the model trained, its performance is compared to the Cox model's as shown by table \@ref(tab:performances). One cannot but admit that the random survival forest perform poorly in terms of concordance index with respect to the Cox model. The latter manages to output a better risk scoring than the ML algorithm. It is thus decided to select the Cox PH model for the rest of the study.

```{r}
load(file = paste0(backup_path, "survival/c_index_cox.Rdata"))
load(file = paste0(backup_path, "survival/c_index_rsf.Rdata"))
```

```{r performances}
tab <- rbind(c_index_cox, 
             c_index_rsf) %>%
  mutate(Train = 100*Train, 
         Test = 100*Test)
rownames(tab) <- c("Cox", "RSF")
tab %>% 
  mykable(title = "Concordance index (%) obtained with Cox model and Random Survival Forest (RSF)", 
          digits = 3)
```

## Portfolio value estimation

In the two previous sections, the portfolio has been partitioned into 3 customer segments and customer lifetime has been estimated by the means of the Cox model. This section's purpose consists in deriving a method to calculate the overall value of the portfolio through the computation of customer lifetime raw value. 

### The model

As said in chapter \@ref(data), it is decided not to use the `CLTV` variable to estimate customer lifetime value since no information has been provided on the computation method. Instead, another method is adopted to predict each client's lifetime value. For this purpose, two inputs are needed namely each customer's survival function as well as the monthly fees represented by the `Monthly_Charges` feature. Based on the CLV formulation proposed by Gupta and Lehmann [@CUSTOMERS_ASSETS], we derive a model aiming at calculating customer lifetime raw value (CLRV) as depicted in equation \@ref(eq:clrv). 

\begin{equation}
    CLRV_i = \sum_{t=0}^{T} \frac{p_i \ r_{i,t}}{(1+a)^t} 
    (\#eq:clrv)
\end{equation}

with, 

- $p_i$ the monthly fee paid by customer $i$,
- $r_{i,t}$ the probability that customer $i$ be in the portfolio at time $t$,
- $a$ the discount factor,
- $T$ the time horizon. 

It may be interesting to note that $p_i$ is time-invariant and corresponds to `Monthly_Charges`. $r_{i,t}$ is computed using the survival function estimated with the Cox model. $a$ is fixed at 8% and $T$ equals 72 months which is the longest lifetime in the data. 

### Customer Lifetime Raw Value

```{r}
load(file = paste0(backup_path, "custvalues/", "custValues_8pct", ".RData"))
load(file = paste0(backup_path, "custvalues/", "custValues_clust", ".RData"))
```

```{r}
custValuesTot <- custValues %>%
  group_by(CustomerID) %>%
  summarise_at(vars(starts_with("v")), 
               sum) 
```

```{r custValuesSum}
tab <- custValuesTot %>%
  select(starts_with("v")) %>%
  colSums() %>%
  format(big.mark = ",") %>%
  data.frame()
rownames(tab) <- c("V lower", "V", "V upper")
colnames(tab) <- ""
tab %>%
  mykable(title = "Portfolio estimated value with 95$\\%$ confidence interval", 
          transp = T)
```


```{r custValuesStats}
tab <- custValuesTot %>%
  pull(v) %>%
  summary() %>%
  unclass() %>%
  data.frame(check.names = FALSE, 
             stringsAsFactors = FALSE)
colnames(tab) <- " " 

tab %>%
  mykable(title = "CLRV Statistical summary", 
          transp = T)
```


```{r clrvDens, fig.cap="Distribution of Customer Lifetime Raw Value"}
knitr::include_graphics(path = "./imgs/clrv_density.png")
```

```{r clrvEvolution, fig.cap="Customer Lifetime Raw Value evolution based on number of months in the portfolio"}
knitr::include_graphics(path = "./imgs/clrv_evolution.png")
```

### Cluster contribution to the portfolio value

```{r}
cluster_prop <- questionr::freq(custValues_clust$cluster) %>%
  pull(`%`)

custValues_clustTot <- custValues_clust %>%
  group_by(cluster, CustomerID) %>%
  summarise_at(vars(starts_with("v")), 
               sum)
```


```{r totValclust}
tab <- custValues_clustTot %>%
  group_by(cluster) %>%
  summarise_at(vars(starts_with("v")), 
               function(v){sum(v) %>%
                   format(big.mark = ",")})  %>%
  mutate(prop = cluster_prop) %>%
  relocate(prop, .after = "cluster")
colnames(tab) <- c("Cluster", "Proportion (%)", "V lower", 
                   "V", "V upper")
tab %>%
  mykable(title = "Total CLRV per cluster", 
          align = rep("c", 5))
```

```{r custValuesclust}
lapply(seq(1, 3), 
       function(c){
         tmp <- custValues_clustTot %>%
           filter(cluster == c) %>%
           pull(v) %>%
           summary() %>%
           unclass() %>%
           data.frame(check.names = FALSE, 
                       stringsAsFactors = FALSE)
         colnames(tmp) <- paste("Cluster", as.character(c))
         tmp %>% 
           t() %>%
           as.data.frame()
       }) %>%
  bind_rows() %>%
  mykable(title = "CLRV statistical summary for each customer segment")
```

```{r clrvDensClust, fig.cap="Distribution of Customer Lifetime Raw Value per cluster"}
knitr::include_graphics(path = "./imgs/clrv_density_per_cluster.png")
```

```{r clrvEvolutionClust, fig.cap="Customer Lifetime Raw Value evolution per cluster based on number of months in the portfolio"}
knitr::include_graphics(path = "./imgs/clrv_evolution_per_cluster.png")
```


### Simulations 

#### Influence of the discount factor on CLRV {-}

```{r portValDiscountTab}
load(file = paste0(backup_path, "custValues/portVal_discount_rate.RData"))
portVal_discount_rate %>%
  column_to_rownames(var = "discount") %>%
  rename(`V Lower` = v_lower, 
         V = v, 
         `V upper` = v_upper) %>%
  mykable(title = "Portfolio value depending on discount rate")
```

```{r clrvDensDiscount, fig.cap="Customer Lifetime Raw Value distribution depending on discount rate"}
knitr::include_graphics(path = "./imgs/clrv_dens_discount_rate.png")
```

```{r clrvEvolDiscount, fig.cap="Customer Lifetime Raw Value evolution depending on discount rate"}
knitr::include_graphics(path = "./imgs/clrv_evolution_discount.png")
```

#### Influence of the contract type on CLRV {-}

```{r}
load(file = paste0(backup_path, "custValues/custVal_month_to_month.RData")) 
```

```{r}
custVal_month_to_month %>%
  mykable(title = "Portfolio estimated value and 95% confidence interval depending on proportion of 'month-to-month' contracts")
```


```{r clrvmonthtomonth, fig.cap="CLRV distribution depending on the proportion of 'month-to-month' contracts"}
knitr::include_graphics(path = "./imgs/clrv_month_to_month.png")
```

```{r clrvmonthtomonthEvol, fig.cap="Portfolio estimated value (Customer Raw Equity) depending on the proportion of 'month-to-month' contracts"}
knitr::include_graphics(path = "./imgs/portVal_month_to_month.png")
```

#### How to increase Customer Lifetime Raw Value? {-}

```{r}
load(file = paste0(backup_path, "custValues/tab_clust2_portVal.RData"))
```

```{r}
tab_clust2_portVal %>%
  dplyr::rename(`Portfolio Value` = V) %>% 
  mykable(title = "Increase in portfolio value after having provided cluster 2 clients with additional services")
```

```{r clust2CLRV, fig.cap="Increase in cluster 2 clients' CLRV after after having provided them with additional services"}
knitr::include_graphics(path = "./imgs/clust2_clrv.png")
```

